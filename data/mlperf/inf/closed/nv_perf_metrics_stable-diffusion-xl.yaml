- benchmark: Benchmark.SDXL
  cores: 56
  gpu: NVIDIA H100-SXM-80GB
  gpu_batch_size:
    clip1: 64
    clip2: 64
    unet: 64
    vae: 8
  gpu_copy_streams: 1
  gpu_inference_streams: 1
  id: 4.1-0043
  input_dtype: int32
  input_format: linear
  metric: Samples/s
  nodes: 1
  num gpu: 8
  offline_expected_qps: 16
  org: NVIDIA
  perf: 16.35
  precision: fp8
  processor: Intel(R) Xeon(R) Platinum 8480C
  scenario: Scenario.Offline
  sys: NVIDIA DGX H100 (8x H100-SXM-80GB TensorRT)
  system: KnownSystem.H100_SXM_80GBx8
  use_graphs: false
  vboost_slider: 1
  wlname: stable-diffusion-xl
- benchmark: Benchmark.SDXL
  cores: 56
  gpu: NVIDIA H100-SXM-80GB
  gpu_batch_size:
    clip1: 16
    clip2: 16
    unet: 16
    vae: 8
  gpu_copy_streams: 1
  gpu_inference_streams: 1
  id: 4.1-0043
  input_dtype: int32
  input_format: linear
  metric: Queries/s
  nodes: 1
  num gpu: 8
  org: NVIDIA
  perf: 15.72
  precision: fp8
  processor: Intel(R) Xeon(R) Platinum 8480C
  scenario: Scenario.Server
  sdxl_batcher_time_limit: 5
  server_target_qps: 16.2
  sys: NVIDIA DGX H100 (8x H100-SXM-80GB TensorRT)
  system: KnownSystem.H100_SXM_80GBx8
  use_graphs: false
  vboost_slider: 1
  wlname: stable-diffusion-xl
- benchmark: Benchmark.SDXL
  cores: 72
  gpu: NVIDIA GH200 Grace Hopper Superchip 144GB
  gpu_batch_size:
    clip1: 64
    clip2: 64
    unet: 64
    vae: 8
  gpu_copy_streams: 1
  gpu_inference_streams: 1
  id: 4.1-0044
  input_dtype: int32
  input_format: linear
  metric: Samples/s
  nodes: 1
  num gpu: 1
  offline_expected_qps: 2.3
  org: NVIDIA
  perf: 2.3
  precision: fp8
  processor: NVIDIA Grace CPU
  scenario: Scenario.Offline
  sys: NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64 TensorRT)
  system: KnownSystem.GH200_144GB_ARMx1
  use_graphs: false
  wlname: stable-diffusion-xl
- benchmark: Benchmark.SDXL
  cores: 72
  gpu: NVIDIA GH200 Grace Hopper Superchip 144GB
  gpu_batch_size:
    clip1: 16
    clip2: 16
    unet: 16
    vae: 8
  gpu_copy_streams: 1
  gpu_inference_streams: 1
  id: 4.1-0044
  input_dtype: int32
  input_format: linear
  metric: Queries/s
  nodes: 1
  num gpu: 1
  org: NVIDIA
  perf: 2.02
  precision: fp8
  processor: NVIDIA Grace CPU
  scenario: Scenario.Server
  sdxl_batcher_time_limit: 3
  server_target_qps: 2.15
  sys: NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64 TensorRT)
  system: KnownSystem.GH200_144GB_ARMx1
  use_graphs: false
  wlname: stable-diffusion-xl
- benchmark: Benchmark.SDXL
  cores: 56
  gpu: NVIDIA H200-SXM-141GB
  gpu_batch_size:
    clip1: 64
    clip2: 64
    unet: 64
    vae: 8
  gpu_copy_streams: 1
  gpu_inference_streams: 1
  id: 4.1-0048
  input_dtype: int32
  input_format: linear
  metric: Samples/s
  nodes: 1
  num gpu: 8
  offline_expected_qps: 16.8
  org: NVIDIA
  perf: 17.42
  precision: fp8
  processor: Intel(R) Xeon(R) Platinum 8480C
  scenario: Scenario.Offline
  sys: NVIDIA H200 (8x H200-SXM-141GB TensorRT)
  system: KnownSystem.H200_SXM_141GBx8
  use_graphs: false
  vboost_slider: 1
  wlname: stable-diffusion-xl
- benchmark: Benchmark.SDXL
  cores: 56
  gpu: NVIDIA H200-SXM-141GB
  gpu_batch_size:
    clip1: 16
    clip2: 16
    unet: 16
    vae: 8
  gpu_copy_streams: 1
  gpu_inference_streams: 1
  id: 4.1-0048
  input_dtype: int32
  input_format: linear
  metric: Queries/s
  nodes: 1
  num gpu: 8
  org: NVIDIA
  perf: 16.78
  precision: fp8
  processor: Intel(R) Xeon(R) Platinum 8480C
  scenario: Scenario.Server
  sdxl_batcher_time_limit: 5
  server_target_qps: 16.9
  sys: NVIDIA H200 (8x H200-SXM-141GB TensorRT)
  system: KnownSystem.H200_SXM_141GBx8
  use_graphs: false
  vboost_slider: 1
  wlname: stable-diffusion-xl
